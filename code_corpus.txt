def __init__(self, vocab_size, d_model, max_len):
  super().__init__()
  self.embedding = nn.Embedding(vocab_size, d_model)
  self.pos_embedding = nn.Parameter(torch.randn(1, max_len, d_model))
 def forward(self, x):
  x = self.embedding(x) + self.pos_embedding[:, :x.size(1), :]
  return x

---CODE_SEPARATOR---

def __init__(self, code_vocab_size, doc_vocab_size, d_model=64, max_len=20):
  super().__init__()
  self.code_encoder = Encoder(code_vocab_size, d_model, max_len)
  self.doc_encoder = Encoder(doc_vocab_size, d_model, max_len)
  self.code_proj = nn.Linear(d_model, d_model)
  self.doc_proj = nn.Linear(d_model, d_model)
 def forward(self, code_ids, doc_ids):
  code_enc = self.code_encoder(code_ids).mean(dim=1)
  doc_enc = self.doc_encoder(doc_ids).mean(dim=1)
  return self.code_proj(code_enc), self.doc_proj(doc_enc)

---CODE_SEPARATOR---

class Encoder(nn.Module):
 def __init__(self, vocab_size, d_model, max_len):
  super().__init__()
  self.embedding = nn.Embedding(vocab_size, d_model)
  self.pos_embedding = nn.Parameter(torch.randn(1, max_len, d_model))
 def forward(self, x):
  x = self.embedding(x) + self.pos_embedding[:, :x.size(1), :]
  return x

---CODE_SEPARATOR---

class CodeDocTransformer(nn.Module):
 def __init__(self, code_vocab_size, doc_vocab_size, d_model=64, max_len=20):
  super().__init__()
  self.code_encoder = Encoder(code_vocab_size, d_model, max_len)
  self.doc_encoder = Encoder(doc_vocab_size, d_model, max_len)
  self.code_proj = nn.Linear(d_model, d_model)
  self.doc_proj = nn.Linear(d_model, d_model)
 def forward(self, code_ids, doc_ids):
  code_enc = self.code_encoder(code_ids).mean(dim=1)
  doc_enc = self.doc_encoder(doc_ids).mean(dim=1)
  return self.code_proj(code_enc), self.doc_proj(doc_enc)

---CODE_SEPARATOR---

def get_sample_data():
 code_batch = torch.tensor([
  [1, 5, 9, 2, 0, 0],
  [3, 6, 2, 0, 0, 0]
 ])  
 doc_batch = torch.tensor([
  [1, 4, 9, 0, 0, 0],
  [3, 6, 0, 0, 0, 0]
 ])
 return code_batch, doc_batch

---CODE_SEPARATOR---

